name: declare

services:
    dashboards:
        container_name: dashboards
        build:
            context: ../
            dockerfile: __declare__/Dockerfile-dashboards
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:5173/"]
            interval: 1s
            timeout: 10s
            retries: 5
        ports:
            - "5173:5173"
        volumes:
            # Mount the dashboards source directory to the container for watching
            - ./../dashboards:/usr/src/app/src/user_dashboards
            # Mount the model definitions directory to the container for watching as well
            - ./../models:/usr/src/app/src/models
        restart: unless-stopped
    hot-model-reloader:
        container_name: hot-model-reloader
        build:
            context: ../
            dockerfile: __declare__/Dockerfile-hot-model-reloader
        depends_on:
            clickhouse:
                condition: service_healthy
        volumes:
            # Mount the model definitions directory to the container for watching
            - ./../models:/usr/src/app/models
        restart: unless-stopped
    serve-models-api:
        container_name: serve-models-api
        build:
            context: ../
            dockerfile: __declare__/Dockerfile-serve-models-api
        ports:
            - "8001:8001"
        depends_on:
            clickhouse:
                condition: service_healthy
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:8001/"]
            interval: 1s
            timeout: 10s
            retries: 5
        restart: unless-stopped
    sql-linter:
        container_name: sql-linter
        image: sqlfluff/sqlfluff:latest
        user: root # Run as root to gain necessary permissions
        volumes:
            - ./../models:/models
        entrypoint: >
            /bin/sh -c "
                # Run sqlfluff lint silently on all files initially
                sqlfluff lint /models --dialect clickhouse && \
                echo \"\" && \

                # Update and install inotify-tools quietly
                apt-get update -qq && \
                apt-get install -y --no-install-recommends inotify-tools > /dev/null 2>&1 && \

                # Clean up to reduce image size
                chmod -R 755 /var/lib/apt/lists && \
                rm -rf /var/lib/apt/lists/* && \

                # Start the inotifywait loop silently
                while true; do \
                    FILE=$$(inotifywait -e modify --format \"%w%f\" -r /models) > /dev/null 2>&1 && \
                    echo \"\" && \
                    sqlfluff lint \"$$FILE\" --dialect clickhouse; \
                    echo \"\" \
                done
            "
        restart: always
    workflow-worker:
        container_name: workflow-worker
        build:
            context: ../
            dockerfile: __declare__/Dockerfile-workflow-worker
        depends_on:
            hatchet-lite:
                condition: service_healthy
        # Use host networking to allow access to localhost:7077
        network_mode: "host"
        volumes:
            - ./../workflows:/usr/src/app/workflows
        restart: unless-stopped
    clickhouse:
        container_name: clickhouse
        image: clickhouse/clickhouse-server
        user: "101:101"
        hostname: clickhouse
        ports:
            # The HTTP api
            - "127.0.0.1:8123:8123"
            # The native protocol
            - "127.0.0.1:9000:9000"
        healthcheck:
            test: wget --no-verbose --tries=1 --spider http://localhost:8123/ping || exit 1
            interval: 100ms
            timeout: 250ms
            retries: 20
        restart: on-failure
        security_opt:
            - seccomp:unconfined
    hatchet-postgres:
        container_name: hatchet-postgres
        image: postgres:15.6
        command: postgres -c 'max_connections=200'
        restart: always
        environment:
            - POSTGRES_USER=hatchet
            - POSTGRES_PASSWORD=hatchet
            - POSTGRES_DB=hatchet
        volumes:
            - hatchet_lite_postgres_data:/var/lib/postgresql/data
        healthcheck:
            test: ["CMD-SHELL", "pg_isready -U hatchet -d hatchet"]
            interval: 1s
            timeout: 10s
            retries: 20
            start_period: 1s
    hatchet-lite:
        container_name: hatchet-lite
        image: ghcr.io/hatchet-dev/hatchet/hatchet-lite:latest
        ports:
            - "8888:8888"
            - "7077:7077"
        depends_on:
            hatchet-postgres:
                condition: service_healthy
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:8888/"]
            interval: 10s
            timeout: 10s
            retries: 5
        environment:
            RABBITMQ_DEFAULT_USER: "user"
            RABBITMQ_DEFAULT_PASS: "password"
            DATABASE_URL: "postgresql://hatchet:hatchet@hatchet-postgres:5432/hatchet?sslmode=disable"
            DATABASE_POSTGRES_PORT: "5432"
            DATABASE_POSTGRES_HOST: "hatchet-postgres"
            SERVER_TASKQUEUE_RABBITMQ_URL: amqp://user:password@localhost:5672/
            SERVER_AUTH_COOKIE_DOMAIN: localhost
            SERVER_AUTH_COOKIE_INSECURE: "t"
            SERVER_GRPC_BIND_ADDRESS: "0.0.0.0"
            SERVER_GRPC_INSECURE: "t"
            SERVER_GRPC_BROADCAST_ADDRESS: localhost:7077
            SERVER_GRPC_PORT: "7077"
            SERVER_URL: http://localhost:8888
            SERVER_AUTH_SET_EMAIL_VERIFIED: "t"
            SERVER_LOGGER_LEVEL: warn
            SERVER_LOGGER_FORMAT: console
            DATABASE_LOGGER_LEVEL: warn
            DATABASE_LOGGER_FORMAT: console
        volumes:
            - "hatchet_lite_rabbitmq_data:/var/lib/rabbitmq/mnesia"
            - "hatchet_lite_config:/config"
        attach: false

volumes:
    hatchet_lite_postgres_data:
    hatchet_lite_rabbitmq_data:
    hatchet_lite_config:
